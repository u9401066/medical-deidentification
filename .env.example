# ============================================================
# 環境變數範例 | Environment Variables Example
# 複製此檔案為 .env 並填入實際值
# Copy this file to .env and fill in actual values
# ============================================================

# === 應用程式設定 | Application Settings ===
APP_NAME=medical-deidentification
APP_ENV=development
LOG_LEVEL=INFO

# === LLM API 金鑰 | LLM API Keys ===
# OpenAI (for GPT-4, GPT-4o)
# OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic (for Claude 3)
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# === 本地 LLM 設定 | Local LLM Settings ===
# Ollama server URL (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Default model for local inference
# Options: qwen2.5:7b, llama3.1:8b, jingyaogong/minimind2
DEFAULT_LOCAL_MODEL=qwen2.5:7b

# === RAG 設定 | RAG Settings ===
# Embedding model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Vector store path
VECTORSTORE_PATH=./regulations/vectorstore

# === 處理設定 | Processing Settings ===
# Chunk size for streaming processing
CHUNK_SIZE=2000
CHUNK_OVERLAP=100

# Maximum tokens for LLM response
MAX_TOKENS=2048

# === 輸出設定 | Output Settings ===
# Output directory for results
OUTPUT_DIR=./data/output/results

# Checkpoint directory for resume support
CHECKPOINT_DIR=./data/output/checkpoints

# === 安全設定 | Security Settings ===
# 請勿在此處放置真實的 API 金鑰
# DO NOT put real API keys here
# 使用環境變數或 secrets manager
# Use environment variables or secrets manager
