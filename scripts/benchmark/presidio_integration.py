"""
Presidio Evaluator Integration | Presidio Evaluator æ•´åˆ

ä½¿ç”¨ Microsoft Presidio Evaluator ç”¢ç”Ÿåˆæˆ PHI è³‡æ–™ä¸¦è©•ä¼°

Presidio Evaluator ç‰¹é»ï¼š
- ä½¿ç”¨ Faker ç”¢ç”ŸçœŸå¯¦æ ¼å¼çš„åˆæˆè³‡æ–™
- æ”¯æ´å¤šç¨® templates å’Œ entity types
- å¯è‡ªè¨‚æ“´å……

å®‰è£ï¼š
    uv add presidio-evaluator

ä½¿ç”¨ï¼š
    python -m scripts.benchmark.presidio_integration generate --count 100 --output data/benchmark/presidio_test.jsonl
    python -m scripts.benchmark.presidio_integration evaluate --data data/benchmark/presidio_test.jsonl
"""

import argparse
import json
import logging
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

logger = logging.getLogger(__name__)


def check_presidio_installed() -> bool:
    """æª¢æŸ¥ presidio-evaluator æ˜¯å¦å·²å®‰è£"""
    try:
        import presidio_evaluator
        return True
    except ImportError:
        return False


def generate_synthetic_data(
    count: int = 100,
    output_path: Path | None = None,
    locale: str = "en_US",
    templates: list[str] | None = None,
) -> list[dict]:
    """
    ä½¿ç”¨ Presidio Evaluator ç”¢ç”Ÿåˆæˆ PHI è³‡æ–™
    
    Args:
        count: ç”¢ç”Ÿçš„æ¨£æœ¬æ•¸
        output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        locale: Faker locale (en_US, zh_TW, etc.)
        templates: ä½¿ç”¨çš„ templates (None = ä½¿ç”¨é è¨­)
    
    Returns:
        ç”¢ç”Ÿçš„è³‡æ–™åˆ—è¡¨
    """
    if not check_presidio_installed():
        raise ImportError(
            "presidio-evaluator not installed. Run: uv add presidio-evaluator"
        )

    from presidio_evaluator.data_generator import PresidioDataGenerator
    from presidio_evaluator.data_generator.faker_extensions import (
        FakerSpansResult,
    )

    # å»ºç«‹ generator
    generator = PresidioDataGenerator(
        locale=locale,
        lower_case_ratio=0.0,  # ä¿æŒåŸå§‹å¤§å°å¯«
    )

    # ä½¿ç”¨é è¨­ templates æˆ–è‡ªè¨‚
    if templates is None:
        # Presidio Evaluator å…§å»º templates
        templates = [
            "My name is {{name}} and I live at {{address}}",
            "Contact me at {{phone_number}} or {{email}}",
            "My SSN is {{ssn}} and my credit card is {{credit_card_number}}",
            "Born on {{date_of_birth}}, I work at {{organization}}",
            "Patient {{name}} was admitted on {{date}} with ID {{medical_record_number}}",
            "Send records to {{name}} at {{address}}, phone {{phone_number}}",
            "The patient, {{name}}, age {{age}}, was seen on {{date}}",
            "Insurance ID: {{insurance_id}}, Member: {{name}}",
            "{{name}} scheduled for {{date}} at {{time}} in room {{room_number}}",
            "Doctor {{name}} referred patient to {{organization}}",
        ]

    # ç”¢ç”Ÿè³‡æ–™
    samples = []
    for i in range(count):
        template = templates[i % len(templates)]

        try:
            result: FakerSpansResult = generator.generate(template)

            sample = {
                "id": f"presidio_{i:05d}",
                "full_text": result.full_text,
                "masked": result.masked,
                "spans": [
                    {
                        "entity_type": span.entity_type,
                        "entity_value": span.entity_value,
                        "start_position": span.start_position,
                        "end_position": span.end_position,
                    }
                    for span in result.spans
                ],
                "template": template,
            }
            samples.append(sample)

        except Exception as e:
            logger.warning(f"Failed to generate sample {i}: {e}")

    # å„²å­˜
    if output_path:
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "w", encoding="utf-8") as f:
            for sample in samples:
                f.write(json.dumps(sample, ensure_ascii=False) + "\n")

        print(f"âœ… ç”¢ç”Ÿ {len(samples)} ç­†è³‡æ–™ï¼Œå„²å­˜è‡³ {output_path}")

    return samples


def generate_taiwan_templates() -> list[str]:
    """
    ç”¢ç”Ÿå°ç£é†«ç™‚æƒ…å¢ƒ templates
    
    æ³¨æ„ï¼šéœ€è¦ä½¿ç”¨ zh_TW locale çš„ Faker
    """
    return [
        "ç—…æ‚£{{name}}ï¼Œèº«åˆ†è­‰è™Ÿ{{id_number}}ï¼Œæ–¼{{date}}å°±è¨º",
        "{{name}}å…ˆç”Ÿ/å¥³å£«ï¼Œå‡ºç”Ÿæ—¥æœŸ{{date_of_birth}}ï¼Œé›»è©±{{phone_number}}",
        "ç—…æ­·è™Ÿï¼š{{medical_record_number}}ï¼Œå§“åï¼š{{name}}ï¼Œåœ°å€ï¼š{{address}}",
        "ä¸»æ²»é†«å¸«{{name}}æ–¼{{date}}é–‹ç«‹è™•æ–¹",
        "è½‰è¨ºå–®ï¼šç—…æ‚£{{name}}è½‰è‡³{{organization}}{{department}}",
        "è¯çµ¡äººï¼š{{name}}ï¼Œæ‰‹æ©Ÿ{{phone_number}}ï¼ŒEmail: {{email}}",
        "ä½é™¢æ—¥æœŸï¼š{{date}}ï¼Œé å®šå‡ºé™¢ï¼š{{date}}ï¼Œç—…æˆ¿{{room_number}}",
        "{{name}}ï¼ˆ{{age}}æ­²ï¼‰ï¼Œå¥ä¿å¡è™Ÿ{{insurance_id}}",
    ]


def run_evaluation(
    data_path: Path,
    model: str = "granite4:1b",
    save_path: Path | None = None,
    limit: int | None = None,
) -> dict:
    """
    ä½¿ç”¨æœ¬å°ˆæ¡ˆçš„ PHI è­˜åˆ¥ç³»çµ±è©•ä¼°åˆæˆè³‡æ–™
    
    Args:
        data_path: åˆæˆè³‡æ–™è·¯å¾‘
        model: Ollama model åç¨±
        save_path: å ±å‘Šå„²å­˜è·¯å¾‘
        limit: é™åˆ¶æ¨£æœ¬æ•¸
    
    Returns:
        è©•ä¼°çµæœæ‘˜è¦
    """
    from scripts.benchmark import PHIEvaluator

    # å˜—è©¦è¼‰å…¥å°ˆæ¡ˆçš„ PHI è­˜åˆ¥ç³»çµ±
    try:
        from core.infrastructure.dspy import (
            create_phi_identifier_from_yaml as create_phi_identifier,
        )

        # å»ºç«‹ detector wrapper
        phi_identifier = create_phi_identifier(model_name=model)

        def detector(text: str) -> list[tuple]:
            result = phi_identifier(text)
            if hasattr(result, 'phi_entities'):
                return [(e.text, e.phi_type) for e in result.phi_entities]
            elif hasattr(result, 'entities'):
                return [(e["text"], e["phi_type"]) for e in result.entities]
            return []

    except ImportError:
        # Fallback: ä½¿ç”¨ç°¡å–®çš„ regex detector ä½œç‚ºç¤ºç¯„
        import re

        PATTERNS = {
            "EMAIL": r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            "PHONE": r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b',
            "SSN": r'\b\d{3}-\d{2}-\d{4}\b',
            "DATE": r'\b\d{1,2}[/-]\d{1,2}[/-]\d{2,4}\b',
        }

        def detector(text: str) -> list[tuple]:
            results = []
            for phi_type, pattern in PATTERNS.items():
                for match in re.finditer(pattern, text):
                    results.append((match.group(), phi_type))
            return results

        print("âš ï¸  ä½¿ç”¨ regex fallback detector (æœªè¼‰å…¥å°ˆæ¡ˆ PHI è­˜åˆ¥ç³»çµ±)")

    # åŸ·è¡Œè©•ä¼°
    evaluator = PHIEvaluator(detector=detector, match_type="partial")
    report = evaluator.evaluate(
        data_path,
        format="presidio",
        limit=limit,
        save_path=save_path,
    )

    return {
        "precision": report.metrics.overall.precision,
        "recall": report.metrics.overall.recall,
        "f1": report.metrics.overall.f1,
        "samples": report.metrics.total_samples,
    }


def main():
    """CLI å…¥å£é»"""
    parser = argparse.ArgumentParser(
        description="Presidio Evaluator æ•´åˆå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # ç”¢ç”Ÿåˆæˆè³‡æ–™
  python -m scripts.benchmark.presidio_integration generate --count 100
  
  # è©•ä¼°
  python -m scripts.benchmark.presidio_integration evaluate --data data/benchmark/presidio_test.jsonl
  
  # å®Œæ•´æµç¨‹
  python -m scripts.benchmark.presidio_integration full --count 50
        """,
    )

    subparsers = parser.add_subparsers(dest="command", help="å‘½ä»¤")

    # generate å­å‘½ä»¤
    gen_parser = subparsers.add_parser("generate", help="ç”¢ç”Ÿåˆæˆè³‡æ–™")
    gen_parser.add_argument("--count", "-n", type=int, default=100, help="æ¨£æœ¬æ•¸")
    gen_parser.add_argument(
        "--output", "-o",
        type=Path,
        default=Path("data/benchmark/presidio_synthetic.jsonl"),
        help="è¼¸å‡ºè·¯å¾‘",
    )
    gen_parser.add_argument("--locale", default="en_US", help="Faker locale")

    # evaluate å­å‘½ä»¤
    eval_parser = subparsers.add_parser("evaluate", help="è©•ä¼°")
    eval_parser.add_argument("--data", "-d", type=Path, required=True, help="è³‡æ–™è·¯å¾‘")
    eval_parser.add_argument("--model", "-m", default="granite4:1b", help="æ¨¡å‹åç¨±")
    eval_parser.add_argument("--output", "-o", type=Path, help="å ±å‘Šè¼¸å‡ºè·¯å¾‘")
    eval_parser.add_argument("--limit", type=int, help="é™åˆ¶æ¨£æœ¬æ•¸")

    # full å­å‘½ä»¤ (ç”¢ç”Ÿ + è©•ä¼°)
    full_parser = subparsers.add_parser("full", help="å®Œæ•´æµç¨‹ (ç”¢ç”Ÿ + è©•ä¼°)")
    full_parser.add_argument("--count", "-n", type=int, default=50, help="æ¨£æœ¬æ•¸")
    full_parser.add_argument("--model", "-m", default="granite4:1b", help="æ¨¡å‹åç¨±")

    args = parser.parse_args()

    if args.command == "generate":
        if not check_presidio_installed():
            print("âŒ presidio-evaluator æœªå®‰è£")
            print("   è«‹åŸ·è¡Œ: uv add presidio-evaluator")
            sys.exit(1)

        generate_synthetic_data(
            count=args.count,
            output_path=args.output,
            locale=args.locale,
        )

    elif args.command == "evaluate":
        result = run_evaluation(
            data_path=args.data,
            model=args.model,
            save_path=args.output,
            limit=args.limit,
        )
        print(f"\nğŸ“Š çµæœ: P={result['precision']:.3f} R={result['recall']:.3f} F1={result['f1']:.3f}")

    elif args.command == "full":
        # ç”¢ç”Ÿ
        data_path = Path("data/benchmark/presidio_synthetic.jsonl")

        if check_presidio_installed():
            generate_synthetic_data(count=args.count, output_path=data_path)
        else:
            print("âŒ presidio-evaluator æœªå®‰è£ï¼Œä½¿ç”¨ç¯„ä¾‹è³‡æ–™")
            # å»ºç«‹ç°¡å–®ç¯„ä¾‹è³‡æ–™
            data_path.parent.mkdir(parents=True, exist_ok=True)
            with open(data_path, "w") as f:
                samples = [
                    {
                        "id": "sample_1",
                        "full_text": "My name is John Smith and I live at 123 Main St.",
                        "spans": [
                            {"entity_type": "PERSON", "entity_value": "John Smith", "start_position": 11, "end_position": 21},
                            {"entity_type": "ADDRESS", "entity_value": "123 Main St", "start_position": 36, "end_position": 47},
                        ]
                    },
                    {
                        "id": "sample_2",
                        "full_text": "Contact me at 555-123-4567 or john@example.com",
                        "spans": [
                            {"entity_type": "PHONE", "entity_value": "555-123-4567", "start_position": 14, "end_position": 26},
                            {"entity_type": "EMAIL", "entity_value": "john@example.com", "start_position": 30, "end_position": 46},
                        ]
                    },
                ]
                for s in samples:
                    f.write(json.dumps(s) + "\n")

        # è©•ä¼°
        result = run_evaluation(data_path=data_path, model=args.model)
        print(f"\nğŸ“Š çµæœ: P={result['precision']:.3f} R={result['recall']:.3f} F1={result['f1']:.3f}")

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
